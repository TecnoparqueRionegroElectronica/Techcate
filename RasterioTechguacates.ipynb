{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EqDn_W1VmY-p"
      },
      "outputs": [],
      "source": [
        "!pip install rasterio opencv-python geopandas shapely --upgrade --no-binary shapely geopandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xCArLZGimRFH"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vxAFur9vd2MG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import geopandas as gpd\n",
        "import rasterio\n",
        "from rasterio.windows import Window\n",
        "import cv2\n",
        "from shapely.geometry import *\n",
        "from urllib.parse import urlparse\n",
        "import csv\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img, ImageDataGenerator\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from sklearn.model_selection import train_test_split, ParameterGrid\n",
        "from google.colab import drive # for mounting drive\n",
        "\n",
        "# --- Configuration ---\n",
        "DATA_PATH = \"/content/drive/My Drive/Colab Notebooks/\"  # Change to your data path\n",
        "IMAGES_DIR = DATA_PATH\n",
        "LABELS_PATH = os.path.join(DATA_PATH, \"labels.geojson\")\n",
        "OUTPUT_DIR = os.path.join(DATA_PATH, \"plant_detection_output\") # Save outputs to Drive\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "IMG_HEIGHT = 32\n",
        "IMG_WIDTH = 32\n",
        "BATCH_SIZE = 1\n",
        "EPOCHS = 5\n",
        "USE_PRETRAINED = True\n",
        "PATCH_SIZE = (IMG_HEIGHT, IMG_WIDTH)\n",
        "VALIDATION_SPLIT = 0.2\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wi6msznSJ2Xl"
      },
      "outputs": [],
      "source": [
        "# Utility functions\n",
        "def get_local_file_uri(file_path):\n",
        "    file_path = os.path.abspath(file_path)\n",
        "    return urlparse(f\"file://{file_path}\").geturl()\n",
        "\n",
        "def create_geojson_from_polygons(polygons, output_path, crs=\"EPSG:4326\"):\n",
        "    gdf = gpd.GeoDataFrame({'geometry': [Polygon(poly) for poly in polygons]})\n",
        "    gdf.crs = crs\n",
        "    gdf.to_file(output_path, driver=\"GeoJSON\")\n",
        "\n",
        "def annotate_image(image_path, output_geojson_path):\n",
        "    with rasterio.open(image_path) as src:\n",
        "        # Calculate width and height of the quarter section\n",
        "        width = src.width // 2\n",
        "        height = src.height // 2\n",
        "\n",
        "        # Read the lower-left quarter, handling different channel counts\n",
        "        window = Window(0, src.height - height, width, height)\n",
        "        if src.count == 1:\n",
        "            img_data = src.read(1, window=window)  # Read single band\n",
        "            img_data = np.expand_dims(img_data, axis=2)  # Add channel dimension\n",
        "        else:\n",
        "            img_data = src.read([1, 2, 3], window=window)\n",
        "            img_data = np.moveaxis(img_data, 0, -1)\n",
        "\n",
        "        # Convert to 8-bit for OpenCV compatibility\n",
        "        img_data = (img_data * 255.0 / img_data.max()).astype(np.uint8)\n",
        "\n",
        "        # Create a compatible OpenCV image (ensure contiguous data)\n",
        "        img = cv2.cvtColor(img_data, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "    if img is None:\n",
        "        raise ValueError(f\"Could not load image: {image_path}\")\n",
        "\n",
        "    print(f\"Annotating: {image_path} (Lower-left quarter)\")\n",
        "\n",
        "    cv2.namedWindow(\"Image Annotation\", cv2.WINDOW_NORMAL)\n",
        "    polygons = []\n",
        "    current_polygon = []\n",
        "\n",
        "    def on_mouse(event, x, y, flags, param):\n",
        "        nonlocal current_polygon, polygons\n",
        "        if event == cv2.EVENT_LBUTTONDOWN:\n",
        "            # Adjust coordinates to full image scale\n",
        "            current_polygon.append([x + width, y + height])\n",
        "        elif event == cv2.EVENT_RBUTTONDOWN:\n",
        "            if len(current_polygon) > 2:\n",
        "                polygons.append(current_polygon.copy())\n",
        "                current_polygon = []\n",
        "                # Adjust coordinates for drawing on the quarter image\n",
        "                cv2.polylines(img, [np.array([[pt[0] - width, pt[1] - height] for pt in polygons[-1]], np.int32)],\n",
        "                              True, (0, 255, 0), 2)\n",
        "                cv2.imshow(\"Image Annotation\", img)\n",
        "\n",
        "    cv2.setMouseCallback(\"Image Annotation\", on_mouse)\n",
        "\n",
        "    print(\"Instructions:\")\n",
        "    print(\"- Left-click to add points to the polygon.\")\n",
        "    print(\"- Right-click to complete the current polygon.\")\n",
        "    print(\"- Press 'q' to finish annotation and save the GeoJSON.\")\n",
        "\n",
        "    while True:\n",
        "        cv2.imshow(\"Image Annotation\", img)\n",
        "        key = cv2.waitKey(1) & 0xFF\n",
        "        if key == ord(\"q\"):\n",
        "            break\n",
        "\n",
        "    cv2.destroyAllWindows()\n",
        "    create_geojson_from_polygons(polygons, output_geojson_path)\n",
        "\n",
        "# --- Data Loading and Preprocessing ---\n",
        "def load_image_data(image_path, labels_path, patch_size=PATCH_SIZE, use_pretrained=USE_PRETRAINED):\n",
        "    \"\"\"Loads data for a single image.\"\"\"\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    # Read GeoJSON once\n",
        "    gdf = gpd.read_file(labels_path)\n",
        "    polygons = gdf.geometry.to_list()\n",
        "\n",
        "    # Open image with rasterio\n",
        "    with rasterio.open(image_path) as src:\n",
        "        for y in range(0, src.height - patch_size[1] + 1, patch_size[1]):\n",
        "            for x in range(0, src.width - patch_size[0] + 1, patch_size[0]):\n",
        "                window = Window(x, y, patch_size[0], patch_size[1])\n",
        "                image = src.read(window=window)\n",
        "                image = np.moveaxis(image, 0, -1)\n",
        "                image = image.astype(np.float32)\n",
        "\n",
        "                # Handle 4-channel images (remove alpha channel)\n",
        "                if image.shape[-1] == 4:\n",
        "                    image = image[:, :, :3]\n",
        "\n",
        "                # Convert to 3 channels if using pretrained model\n",
        "                if use_pretrained and image.shape[-1] != 3:\n",
        "                    image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
        "\n",
        "                # Normalize data\n",
        "                image = image / 255.0\n",
        "\n",
        "                images.append(image)\n",
        "                center_point = Point(x + patch_size[0] / 2, y + patch_size[1] / 2)\n",
        "                label = 1 if any(polygon.contains(center_point) for polygon in polygons) else 0\n",
        "                labels.append(label)\n",
        "\n",
        "    return np.array(images), np.array(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJnyJVKxJ23D"
      },
      "outputs": [],
      "source": [
        "# --- Model Creation ---\n",
        "def create_model(input_shape, num_classes=1, use_pretrained=USE_PRETRAINED, trainable_layers=10 ):\n",
        "    if use_pretrained:\n",
        "        # Ensure input_shape has 3 channels\n",
        "        if input_shape[-1] != 3:\n",
        "            input_shape = (*input_shape[:-1], 3)\n",
        "        base_model = ResNet50(weights='imagenet', include_top=False, input_tensor=Input(shape=input_shape))\n",
        "        for layer in base_model.layers[:-trainable_layers]:\n",
        "            layer.trainable = True\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(base_model)\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(32, activation='relu'))\n",
        "        model.add(Dense(num_classes, activation='sigmoid'))\n",
        "        return model\n",
        "\n",
        "    else:\n",
        "        model = Sequential()\n",
        "        # Correct input_shape for the first Conv2D layer (without batch dimension)\n",
        "        model.add(Conv2D(16, (3, 3), activation='relu', input_shape=input_shape))\n",
        "        model.add(MaxPooling2D((2, 2)))\n",
        "        model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "        model.add(MaxPooling2D((2, 2)))\n",
        "        model.add(Flatten())\n",
        "\n",
        "        # Calculate Dense layer input size after Flatten - No need to build the model here\n",
        "        dense_input_size = np.prod(model.output_shape[1:])\n",
        "        model.add(Dense(dense_input_size // 2, activation='relu'))\n",
        "        model.add(Dense(num_classes, activation='sigmoid'))\n",
        "        return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "odI7tQqvKNDj"
      },
      "outputs": [],
      "source": [
        "# --- Function to classify patches of an image using TensorFlow Lite ---\n",
        "def classify_patches_tflite(interpreter, image, patch_size=PATCH_SIZE):\n",
        "    height, width, _ = image.shape\n",
        "    predictions = []\n",
        "\n",
        "    input_details = interpreter.get_input_details()\n",
        "    output_details = interpreter.get_output_details()\n",
        "\n",
        "    input_scale, input_zero_point = input_details[0]['quantization']\n",
        "\n",
        "    for y in range(0, height - patch_size[1] + 1, patch_size[1]):\n",
        "        for x in range(0, width - patch_size[0] + 1, patch_size[0]):\n",
        "            patch = image[y:y + patch_size[1], x:x + patch_size[0]]\n",
        "            patch = patch / 255.0  # Normalize patch\n",
        "            patch = np.expand_dims(patch, axis=0).astype(np.float32) # Add batch dimension\n",
        "\n",
        "            # Set tensor and invoke the interpreter\n",
        "            interpreter.set_tensor(input_details[0]['index'], patch)\n",
        "            interpreter.invoke()\n",
        "            output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "            prediction = output_data[0][0]\n",
        "\n",
        "            # --- DEBUG: Save patch with prediction value ---\n",
        "            patch_filename = f\"patch_{y}_{x}_pred_{prediction:.2f}.png\"\n",
        "            patch_path = os.path.join(OUTPUT_DIR, patch_filename)\n",
        "            cv2.imwrite(patch_path, patch * 255.0)\n",
        "\n",
        "            predictions.append(((x, y), prediction))\n",
        "\n",
        "    return predictions\n",
        "\n",
        "def train_model(input_shape, train_images, train_labels, val_images, val_labels, epochs, batch_size, use_pretrained=USE_PRETRAINED):\n",
        "    model = create_model(input_shape, use_pretrained=use_pretrained)\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # --- Data Augmentation ---\n",
        "    datagen = ImageDataGenerator(\n",
        "        rotation_range=20,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest'\n",
        "    )\n",
        "    datagen.fit(train_images)\n",
        "\n",
        "    # Train the model using the data generator\n",
        "    model.fit(\n",
        "        datagen.flow(train_images, train_labels, batch_size=batch_size),\n",
        "        epochs=epochs,\n",
        "        validation_data=(val_images, val_labels),\n",
        "    )\n",
        "\n",
        "    # Evaluate the model on the validation set\n",
        "    _, val_accuracy = model.evaluate(val_images, val_labels, verbose=0)\n",
        "    print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "    return model, val_accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x8n5maQTUb47"
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    image_files = [\n",
        "        f for f in os.listdir(IMAGES_DIR)\n",
        "        if f.lower().endswith(('.jpg', '.png', '.jpeg', '.tif', '.tiff'))\n",
        "    ]\n",
        "    if not image_files:\n",
        "        raise FileNotFoundError(\"No images found in the dataset directory.\")\n",
        "    first_image_path = os.path.join(DATA_PATH, image_files[0])\n",
        "    if not os.path.exists(LABELS_PATH):\n",
        "        annotate_image(first_image_path, LABELS_PATH)\n",
        "\n",
        "    # --- Parameter Grid for Exploration ---\n",
        "    param_grid = {\n",
        "        'patch_size': [(32, 32)],  # Start with a single patch size\n",
        "        'batch_size': [1],  # Start with a single batch size\n",
        "        'epochs': [5],  # Start with a small number of epochs\n",
        "    }\n",
        "\n",
        "    best_accuracy = 0.0\n",
        "    best_model_path = None\n",
        "    # Alternative training function\n",
        "    train_files, val_files = train_test_split(image_files, test_size=VALIDATION_SPLIT, random_state=42)\n",
        "\n",
        "    # --- Annotate the First Training Image (if needed) ---\n",
        "    first_image_path = os.path.join(DATA_PATH, train_files[0])\n",
        "    if not os.path.exists(LABELS_PATH):\n",
        "        annotate_image(first_image_path, LABELS_PATH)\n",
        "\n",
        "    best_accuracy = 0.0\n",
        "    best_model_path = None\n",
        "\n",
        "    # --- Training Loop (Choose ResNet or Sequential) ---\n",
        "    for model_type in [\"resnet\", \"sequential\"]:\n",
        "        print(f\"Training {model_type} model...\")\n",
        "        for params in ParameterGrid(param_grid):\n",
        "            print(f\"Training with parameters: {params}\")\n",
        "            patch_size = params['patch_size']\n",
        "            batch_size = params['batch_size']\n",
        "            epochs = params['epochs']\n",
        "\n",
        "            # --- Load Training and Validation Data ---\n",
        "            train_images, train_labels = [], []\n",
        "            for train_file in train_files:\n",
        "                image_path = os.path.join(IMAGES_DIR, train_file)\n",
        "                images, labels = load_image_data(image_path, LABELS_PATH, patch_size=patch_size, use_pretrained=(model_type == \"resnet\"))\n",
        "                train_images.extend(images)\n",
        "                train_labels.extend(labels)\n",
        "            train_images = np.array(train_images)\n",
        "            train_labels = np.array(train_labels)\n",
        "\n",
        "            val_images, val_labels = [], []\n",
        "            for val_file in val_files:\n",
        "                image_path = os.path.join(IMAGES_DIR, val_file)\n",
        "                images, labels = load_image_data(image_path, LABELS_PATH, patch_size=patch_size, use_pretrained=(model_type == \"resnet\"))\n",
        "                val_images.extend(images)\n",
        "                val_labels.extend(labels)\n",
        "            val_images = np.array(val_images)\n",
        "            val_labels = np.array(val_labels)\n",
        "\n",
        "            # Get input shape from training data\n",
        "            input_shape = train_images[0].shape\n",
        "\n",
        "            # Train model with data augmentation\n",
        "            model, val_accuracy = train_model(\n",
        "                input_shape, train_images, train_labels, val_images, val_labels, epochs, batch_size, use_pretrained=(model_type == \"resnet\")\n",
        "            )\n",
        "\n",
        "            # --- Convert to TensorFlow Lite ---\n",
        "            converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "            tflite_model = converter.convert()\n",
        "\n",
        "            # --- Save TensorFlow Lite Model ---\n",
        "            tflite_model_filename = f\"{model_type}_model_patch{patch_size[0]}_batch{batch_size}_epochs{epochs}.tflite\"\n",
        "            tflite_model_path = os.path.join(OUTPUT_DIR, tflite_model_filename)\n",
        "            with open(tflite_model_path, 'wb') as f:\n",
        "                f.write(tflite_model)\n",
        "            print(f\"TFLite model saved to: {tflite_model_path}\")\n",
        "\n",
        "            # --- Update Best Model ---\n",
        "            if val_accuracy > best_accuracy:\n",
        "                best_accuracy = val_accuracy\n",
        "                best_model_path = tflite_model_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yVpWw1jFKamj"
      },
      "outputs": [],
      "source": [
        "# --- Prediction on Unseen Images (using best TFLite model) ---\n",
        "if best_model_path is not None:\n",
        "    print(f\"Loading best model from: {best_model_path}\")\n",
        "    interpreter = tf.lite.Interpreter(model_path=best_model_path)\n",
        "    interpreter.allocate_tensors()\n",
        "\n",
        "    for img_file in image_files:\n",
        "        print(f\"Analyzing: {img_file}\")\n",
        "        img_path = os.path.join(IMAGES_DIR, img_file)\n",
        "\n",
        "        # Load and preprocess image\n",
        "        with rasterio.open(img_path) as src:\n",
        "            height = src.height\n",
        "            width = src.width\n",
        "            profile = src.profile  # Get rasterio profile for saving\n",
        "            image = src.read()\n",
        "            image = np.moveaxis(image, 0, -1)\n",
        "            image = image.astype(np.float32)\n",
        "\n",
        "        # Predict on patches\n",
        "        predictions = classify_patches_tflite(interpreter, image, patch_size=PATCH_SIZE)\n",
        "\n",
        "        # --- DEBUGGING OUTPUTS ---\n",
        "        # 1. Save predictions to a text file:\n",
        "        with open(os.path.join(OUTPUT_DIR, f\"predictions_{img_file[:-4]}.txt\"), \"w\") as f:\n",
        "            for (x, y), pred in predictions:\n",
        "                f.write(f\"Patch at ({x}, {y}): Prediction = {pred:.4f}\\n\")\n",
        "\n",
        "        # 2. Visualize patches with high and low predictions:\n",
        "        for (x, y), pred in predictions:\n",
        "            if pred > 0.7:\n",
        "                patch = image[y:y + PATCH_SIZE[1], x:x + PATCH_SIZE[0]]\n",
        "                cv2.imwrite(os.path.join(OUTPUT_DIR, f\"high_pred_patch_{y}_{x}.png\"), patch * 255.0)\n",
        "            if pred < 0.3:\n",
        "                patch = image[y:y + PATCH_SIZE[1], x:x + PATCH_SIZE[0]]\n",
        "                cv2.imwrite(os.path.join(OUTPUT_DIR, f\"low_pred_patch_{y}_{x}.png\"), patch * 255.0)\n",
        "\n",
        "        # 3. Print summary statistics of predictions:\n",
        "        preds_array = np.array([pred for (_, _), pred in predictions])\n",
        "        print(f\"Prediction Statistics (Mean: {preds_array.mean():.4f}, \"\n",
        "              f\"Std: {preds_array.std():.4f}, Max: {preds_array.max():.4f})\")\n",
        "        # --- END OF DEBUGGING OUTPUTS ---\n",
        "\n",
        "        # Visualize and save image\n",
        "        output_image = visualize_predictions(image, predictions, threshold=0.2)\n",
        "        output_image_path = os.path.join(OUTPUT_DIR, f\"predicted_{img_file}\")\n",
        "        save_image(output_image, output_image_path)\n",
        "\n",
        "        # Save predicted ROIs as GeoJSON\n",
        "        output_geojson_path = os.path.join(OUTPUT_DIR, f\"predicted_{img_file[:-4]}.geojson\")\n",
        "        save_predicted_rois(predictions, img_path, output_geojson_path, threshold=0.1)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}